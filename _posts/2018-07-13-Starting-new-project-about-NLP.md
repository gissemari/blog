---
layout: post
title: "Starting a new project in NLP"
date: 2018-06-22
---

After finishing my project about energy disaggregation and VRNN, we had the idea to continue working with latent variables. My advisor mentioned the additional significance that latent variables can have among semantic tasks sush as intention, opinion or style recognition/generation. So I started a new adventure by searching for the state of the art. When I start a new exploration of the related literature of some topic I love to report it in an excel. I start with the usual fields like Title, Author, Conference and Year. In a NLP topic, specially approaching it with deep learning and latent variables in the 2010s, I guess the year plays an important role because this field is developing very fast. Other fields that I add are Task/Problem, Datasets and Baselines. These fields give me ideas against what works I want to measure my own work.

(update 2018-09-01)
After reading about sequence-to-sequence (seq2seq) models, I decided to try to do something with the representation of certain words in the sentences. I want to understand why and how some sentences can have similar words but different meanings and the other way around, have different words para but similar meanings (paraphrasing). I decided to continue using variational components in the models and I found interesting works, as RNN-VAE, RNN-VAE and SC-LSTM.